<html>
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Python基于淘宝用户行为分析 | 王安琪的数据分析项目</title>
<link rel="shortcut icon" href="https://Angie-DA.github.io/favicon.ico?v=1647760265899">
<link href="https://cdn.jsdelivr.net/npm/remixicon@2.3.0/fonts/remixicon.css" rel="stylesheet">
<link rel="stylesheet" href="https://Angie-DA.github.io/styles/main.css">
<link rel="alternate" type="application/atom+xml" title="Python基于淘宝用户行为分析 | 王安琪的数据分析项目 - Atom Feed" href="https://Angie-DA.github.io/atom.xml">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">



    <meta name="description" content="调用包
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import json
import matp..." />
    <meta name="keywords" content="" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
    <script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href="https://Angie-DA.github.io">
  <img class="avatar" src="https://Angie-DA.github.io/images/avatar.png?v=1647760265899" alt="">
  </a>
  <h1 class="site-title">
    王安琪的数据分析项目
  </h1>
  <p class="site-description">
    初级DA，请多多指教😆😆
  </p>
  <div class="menu-container">
    
      
        <a href="https://Angie-DA.github.io" class="menu">
          主页
        </a>
      
    
      
        <a href="https://Angie-DA.github.io/archives" class="menu">
          文章
        </a>
      
    
      
        <a href="https://Angie-DA.github.io/tags" class="menu">
          标签
        </a>
      
    
  </div>
  <div class="social-container">
    
      
        <a href="https://github.com/xuyj1111" target="_blank">
          <i class="ri-github-line"></i>
        </a>
      
    
      
    
      
    
      
    
      
    
  </div>
  <form id="gridea-search-form" action="https://Angie-DA.github.io/search/">
    <input name="q" />
  </form>
</div>

        <div class="post-detail">
          <article class="post">
            <h2 class="post-title">
              Python基于淘宝用户行为分析
            </h2>
            <div class="post-info">
              <span>
                2022-03-20
              </span>
              <span>
                25 min read
              </span>
              
            </div>
            
            <div class="post-content-wrapper">
              <div class="post-content">
                <p>调用包</p>
<pre><code class="language-python">import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import json
import matplotlib


from pyecharts.globals import CurrentConfig, NotebookType
from pyecharts import options as opts


from pyecharts.charts import *
from pyecharts.globals import ThemeType

CurrentConfig.NOTEBOOK_TYPE = NotebookType.JUPYTER_NOTEBOOK
</code></pre>
<h3 id="数据读取">数据读取</h3>
<pre><code class="language-python"># 数据量过大，这里只选取前100w行
# 根据官网介绍给定列名,具有可读性

columns=[&quot;userid&quot;, 'itemid', 'categoryid', 'type', 'timestamp']
data = pd.read_csv('E:/UserBehavior.csv',
                   engine='python',
                   encoding='utf-8',
                   names=columns,
                   chunksize=1000000,
                   iterator=True)

plt.rcParams['font.sans-serif'] = 'SimHei'
# plt.rcParams['axes.unicode_minus'] = False
# plt.style.use('ggplot')
</code></pre>
<pre><code class="language-python">dataframe = data.get_chunk(1000000)
</code></pre>
<h4 id="查看数据的基本信息">查看数据的基本信息</h4>
<pre><code class="language-python">dataframe.info()
</code></pre>
<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 1000000 entries, 0 to 999999
Data columns (total 5 columns):
 #   Column      Non-Null Count    Dtype 
---  ------      --------------    ----- 
 0   userid      1000000 non-null  int64 
 1   itemid      1000000 non-null  int64 
 2   categoryid  1000000 non-null  int64 
 3   type        1000000 non-null  object
 4   timestamp   1000000 non-null  int64 
dtypes: int64(4), object(1)
memory usage: 38.1+ MB
</code></pre>
<h3 id="数据清洗">数据清洗</h3>
<pre><code class="language-python">dataframe.isnull().sum()
</code></pre>
<pre><code>userid        0
itemid        0
categoryid    0
type          0
timestamp     0
dtype: int64
</code></pre>
<h4 id="查看数据没有空值的数据的个数">查看数据没有空值的数据的个数</h4>
<pre><code class="language-python">dataframe.nunique()
</code></pre>
<pre><code>userid          9739
itemid        399114
categoryid      5796
type               4
timestamp     499049
dtype: int64
</code></pre>
<h4 id="查看数据的前n条">查看数据的前n条</h4>
<pre><code class="language-python">dataframe.head(n=11)
</code></pre>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>userid</th>
      <th>itemid</th>
      <th>categoryid</th>
      <th>type</th>
      <th>timestamp</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>2268318</td>
      <td>2520377</td>
      <td>pv</td>
      <td>1511544070</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>2333346</td>
      <td>2520771</td>
      <td>pv</td>
      <td>1511561733</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>2576651</td>
      <td>149192</td>
      <td>pv</td>
      <td>1511572885</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>3830808</td>
      <td>4181361</td>
      <td>pv</td>
      <td>1511593493</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>4365585</td>
      <td>2520377</td>
      <td>pv</td>
      <td>1511596146</td>
    </tr>
    <tr>
      <th>5</th>
      <td>1</td>
      <td>4606018</td>
      <td>2735466</td>
      <td>pv</td>
      <td>1511616481</td>
    </tr>
    <tr>
      <th>6</th>
      <td>1</td>
      <td>230380</td>
      <td>411153</td>
      <td>pv</td>
      <td>1511644942</td>
    </tr>
    <tr>
      <th>7</th>
      <td>1</td>
      <td>3827899</td>
      <td>2920476</td>
      <td>pv</td>
      <td>1511713473</td>
    </tr>
    <tr>
      <th>8</th>
      <td>1</td>
      <td>3745169</td>
      <td>2891509</td>
      <td>pv</td>
      <td>1511725471</td>
    </tr>
    <tr>
      <th>9</th>
      <td>1</td>
      <td>1531036</td>
      <td>2920476</td>
      <td>pv</td>
      <td>1511733732</td>
    </tr>
    <tr>
      <th>10</th>
      <td>1</td>
      <td>2266567</td>
      <td>4145813</td>
      <td>pv</td>
      <td>1511741471</td>
    </tr>
  </tbody>
</table>
<h4 id="转换类型-截取数据-重新排列">转换类型、截取数据、重新排列</h4>
<pre><code class="language-python"># 删除重复值，结果一样数据无重复有效数据
dataframe.drop_duplicates(subset=['userid','itemid','type','timestamp'],keep='first',inplace=True)
dataframe.nunique()
</code></pre>
<pre><code>userid          9739
itemid        399114
categoryid      5796
type               4
timestamp     499049
dtype: int64
</code></pre>
<pre><code class="language-python"># 将时间戳转为日期，从原数据的int64转化为日期类型
import datetime

# to_datetime的默认时区不是中国需要改成北京时间+8h
dataframe['time'] = pd.to_datetime(dataframe['timestamp'],unit='s')+datetime.timedelta(hours = 8)
dataframe.head(n=5)
dataframe.info()

# 只截取2017.11.25-2017.12.3期间的数据
startTime = datetime.datetime.strptime(&quot;2017-11-25 00:00:00&quot;,&quot;%Y-%m-%d %H:%M:%S&quot;)
endTime = datetime.datetime.strptime(&quot;2017-12-3 23:59:59&quot;,&quot;%Y-%m-%d %H:%M:%S&quot;)
# print(type(startTime))

dataframe = dataframe[(dataframe.time&gt;=startTime)&amp;(dataframe.time&lt;=endTime)]
# 删除原索引重新排列新的索引
dataframe = dataframe.reset_index(drop=True)

# 拆分日期和小时
dataframe['date']=dataframe.time.dt.date
dataframe['hour']=dataframe.time.dt.hour

#删除原数据列的时间戳属性
dataframe.drop('timestamp',inplace=True, axis=1)
</code></pre>
<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
Int64Index: 1000000 entries, 0 to 999999
Data columns (total 6 columns):
 #   Column      Non-Null Count    Dtype         
---  ------      --------------    -----         
 0   userid      1000000 non-null  int64         
 1   itemid      1000000 non-null  int64         
 2   categoryid  1000000 non-null  int64         
 3   type        1000000 non-null  object        
 4   timestamp   1000000 non-null  int64         
 5   time        1000000 non-null  datetime64[ns]
dtypes: datetime64[ns](1), int64(4), object(1)
memory usage: 53.4+ MB
</code></pre>
<pre><code class="language-python">dataframe.head()
</code></pre>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>userid</th>
      <th>itemid</th>
      <th>categoryid</th>
      <th>type</th>
      <th>time</th>
      <th>date</th>
      <th>hour</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>2268318</td>
      <td>2520377</td>
      <td>pv</td>
      <td>2017-11-25 01:21:10</td>
      <td>2017-11-25</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>2333346</td>
      <td>2520771</td>
      <td>pv</td>
      <td>2017-11-25 06:15:33</td>
      <td>2017-11-25</td>
      <td>6</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>2576651</td>
      <td>149192</td>
      <td>pv</td>
      <td>2017-11-25 09:21:25</td>
      <td>2017-11-25</td>
      <td>9</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>3830808</td>
      <td>4181361</td>
      <td>pv</td>
      <td>2017-11-25 15:04:53</td>
      <td>2017-11-25</td>
      <td>15</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>4365585</td>
      <td>2520377</td>
      <td>pv</td>
      <td>2017-11-25 15:49:06</td>
      <td>2017-11-25</td>
      <td>15</td>
    </tr>
  </tbody>
</table>
<pre><code class="language-python"># 描述性统计数据，科学计数法表示
dataframe.describe()
</code></pre>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>userid</th>
      <th>itemid</th>
      <th>categoryid</th>
      <th>hour</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>9.995300e+05</td>
      <td>9.995300e+05</td>
      <td>9.995300e+05</td>
      <td>999530.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>4.299721e+05</td>
      <td>2.577625e+06</td>
      <td>2.706119e+06</td>
      <td>14.898745</td>
    </tr>
    <tr>
      <th>std</th>
      <td>4.353251e+05</td>
      <td>1.488870e+06</td>
      <td>1.464049e+06</td>
      <td>6.117604</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1.000000e+00</td>
      <td>7.200000e+01</td>
      <td>2.171000e+03</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>1.091610e+05</td>
      <td>1.292370e+06</td>
      <td>1.343555e+06</td>
      <td>11.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>1.216220e+05</td>
      <td>2.575767e+06</td>
      <td>2.693696e+06</td>
      <td>16.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>1.005419e+06</td>
      <td>3.861783e+06</td>
      <td>4.145813e+06</td>
      <td>20.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>1.018011e+06</td>
      <td>5.163057e+06</td>
      <td>5.161669e+06</td>
      <td>23.000000</td>
    </tr>
  </tbody>
</table>
<h4 id="数据清洗结果">数据清洗结果</h4>
<pre><code class="language-python">print('数据清洗后共有{}行记录，{}列字段，字段分别为{}'.format(dataframe.shape[0],dataframe.shape[1],dataframe.columns.tolist()))
</code></pre>
<pre><code>数据清洗后共有999530行记录，7列字段，字段分别为['userid', 'itemid', 'categoryid', 'type', 'time', 'date', 'hour']
</code></pre>
<h3 id="用户数据分析">用户数据分析</h3>
<pre><code class="language-python"># 有效时间内总用户数量，有操作的商品数量及类目
#     独立访客数UV
total_unique_users = dataframe.userid.nunique()
#     有操作的商品
total_unique_itemid = dataframe.itemid.nunique()
#     有操作的商品类目
total_unique_categoryid = dataframe.categoryid.nunique()
#     付费用户数
user_bought_count = dataframe[dataframe['type']=='buy'].userid.nunique()
#     非付费用户数
user_nobought_count = total_unique_users - user_bought_count
</code></pre>
<h4 id="输出当前数据各栏目计数">输出当前数据各栏目计数</h4>
<pre><code class="language-python">total={'UV':[total_unique_users],'商品数':[total_unique_itemid],'类目数':[total_unique_categoryid],'付费用户数':[user_bought_count],'非付费用户数':[user_nobought_count]}
totalnew= pd.DataFrame(total,index = [''])
totalnew
</code></pre>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>UV</th>
      <th>商品数</th>
      <th>类目数</th>
      <th>付费用户数</th>
      <th>非付费用户数</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th></th>
      <td>9739</td>
      <td>398971</td>
      <td>5793</td>
      <td>6689</td>
      <td>3050</td>
    </tr>
  </tbody>
</table>
<h4 id="用户复购率">用户复购率</h4>
<p>用户复购率=购买2次及以上用户数/总购买用户数</p>
<pre><code class="language-python">groupby_userid = dataframe.groupby('userid')
user_type = groupby_userid.type.value_counts().unstack()  # 使用unstack进行不堆叠操作，列方向上的索引转成行方向的索引
user_type.tail()
</code></pre>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>type</th>
      <th>buy</th>
      <th>cart</th>
      <th>fav</th>
      <th>pv</th>
    </tr>
    <tr>
      <th>userid</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1017990</th>
      <td>NaN</td>
      <td>3.0</td>
      <td>NaN</td>
      <td>56.0</td>
    </tr>
    <tr>
      <th>1017994</th>
      <td>NaN</td>
      <td>3.0</td>
      <td>3.0</td>
      <td>29.0</td>
    </tr>
    <tr>
      <th>1017997</th>
      <td>2.0</td>
      <td>NaN</td>
      <td>3.0</td>
      <td>90.0</td>
    </tr>
    <tr>
      <th>1018000</th>
      <td>NaN</td>
      <td>4.0</td>
      <td>NaN</td>
      <td>181.0</td>
    </tr>
    <tr>
      <th>1018011</th>
      <td>1.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>41.0</td>
    </tr>
  </tbody>
</table>
<h4 id="可视化图表">可视化图表</h4>
<pre><code class="language-python"># 提取数据
type_series = dataframe.type.value_counts()
</code></pre>
<h5 id="饼图-用户行为占比">饼图-用户行为占比</h5>
<pre><code class="language-python">plt.figure(figsize = (5,5), dpi = 100)
plt.pie(type_series,
        labels=type_series.index,
        autopct='%1.2f%%', 
        pctdistance = 0.8, 
        counterclock = False, 
        wedgeprops = {'width':0.4})
plt.title('用户行为占比')
plt.show()
</code></pre>
<figure data-type="image" tabindex="1"><img src="https://Angie-DA.github.io/post-images/1647759783333.png" alt="" loading="lazy"></figure>
<h5 id="动态曲线-每日pv-uv">动态曲线-每日pv、uv</h5>
<pre><code class="language-python">#提取数据
pv_day = dataframe[dataframe.type =='pv'].groupby('date')['type'].count()
uv_day = dataframe[dataframe.type =='pv'].drop_duplicates(['userid','date']).groupby('date')['userid'].count()
#转换成图表所需的格式（list）
#1、日期（list.index）
date = pv_day.index
#2、pv、uv（list.values）
pv = np.around(pv_day.values/10000,decimals=2)
# uv = np.around(uv_day.values,decimals=2)
uv=uv_day
</code></pre>
<pre><code class="language-python"># 制作曲线图表
x=list(date)
y1=pv
y2=uv
pvuv_day_line = (Line(init_opts=opts.InitOpts(theme=ThemeType.DARK)) #主题设置
       .add_xaxis(x) #x轴数据源
       .add_yaxis('pv',#图例名字
                  y1, #y1轴数据源
                  label_opts=opts.LabelOpts(is_show=False), #不显示数据标签
                 )
       .add_yaxis('uv',#图例名字
                  yaxis_index=1, #Y的双轴1号索引（区别于y1轴）
                  y_axis=y2, #y2轴数据源
                  label_opts=opts.LabelOpts(is_show=False) #不显示数据标签
                 ) 
        .extend_axis( #y2的轴设置 
                    yaxis=opts.AxisOpts(
                                        name='uv',#轴名字
                                        min_=5000,#轴起点值
                                        max_=15000, #轴最大值
                                        interval=1000, #轴区间间隔
                                        axislabel_opts=opts.LabelOpts(formatter=&quot;{value} 人&quot;) #轴数据标签格式设置
                                         )
                    )
        .set_global_opts( #全局设置
                        tooltip_opts=opts.TooltipOpts(is_show=True,trigger=&quot;axis&quot;,axis_pointer_type='cross'), #随鼠标位置显示xy轴的数据、聚焦形式(交叉)
                        xaxis_opts=opts.AxisOpts(type_='category',axispointer_opts=opts.AxisPointerOpts(is_show=True,type_=&quot;shadow&quot;)),#随鼠标位置凸显x轴长条、凸显形式（阴影）
                        yaxis_opts=opts.AxisOpts(name='pv',axislabel_opts=opts.LabelOpts(formatter=&quot;{value} 万次&quot;)),#y1轴(默认轴)名字、轴数据标签格式设置
                        title_opts=opts.TitleOpts(title=&quot;每日pv和uv&quot;) #标题        
                         )              
            )
pvuv_day_line.render_notebook() #展示图表
</code></pre>
<figure data-type="image" tabindex="2"><img src="https://Angie-DA.github.io/post-images/1647759879704.png" alt="" loading="lazy"></figure>
<h5 id="漏斗图-用户行为">漏斗图-用户行为</h5>
<p>第一层：用户全部行为（pv、buy、cart、fav）</p>
<p>第二层：收藏/加购行为（cart/fav）</p>
<p>第三层：付费行为（buy）</p>
<p>目的：分析用户行为的转化率</p>
<p>用户各行为数据计算方式</p>
<pre><code class="language-python"># 有效日期9天内各个行为的操作总数，每日平均操作数，每日平均操作用户数记录
type_df=pd.DataFrame([type_series,type_series/9,type_series/total_unique_users],
                     index=['total','avg_day','avg_user'])

# 付费用户行为记录
type_df.loc['paying_user']=dataframe[dataframe['userid'].isin(dataframe[dataframe['type']=='buy']['userid'])].type.value_counts()
type_df
</code></pre>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>pv</th>
      <th>cart</th>
      <th>fav</th>
      <th>buy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>total</th>
      <td>895636.000000</td>
      <td>55447.000000</td>
      <td>28088.000000</td>
      <td>20359.000000</td>
    </tr>
    <tr>
      <th>avg_day</th>
      <td>99515.111111</td>
      <td>6160.777778</td>
      <td>3120.888889</td>
      <td>2262.111111</td>
    </tr>
    <tr>
      <th>avg_user</th>
      <td>91.963857</td>
      <td>5.693295</td>
      <td>2.884074</td>
      <td>2.090461</td>
    </tr>
    <tr>
      <th>paying_user</th>
      <td>673147.000000</td>
      <td>43072.000000</td>
      <td>20373.000000</td>
      <td>20359.000000</td>
    </tr>
  </tbody>
</table>
<pre><code class="language-python"># 提取type用户行为列中的每一个行为数据
pv_df = dataframe[dataframe['type']=='pv']
buy_df = dataframe[dataframe['type']=='buy']
cart_df = dataframe[dataframe['type']=='cart']
fav_df = dataframe[dataframe['type']=='fav']
</code></pre>
<pre><code class="language-python"># 方式1 点击-&gt;加购-&gt;购买
pv_cart_df = pd.merge(left=pv_df,right=cart_df,how='inner',on=['userid','itemid','categoryid'],suffixes=('_pv','_cart'))
cart_buy_df = pd.merge(left=cart_df,right=buy_df,how='inner',on=['userid','itemid','categoryid'],suffixes=('_cart','_buy'))
count_users_pv_cart = pv_cart_df[pv_cart_df.time_pv &lt; pv_cart_df.time_cart].userid.nunique()
count_users_cart_buy = cart_buy_df[cart_buy_df.time_cart &lt; cart_buy_df.time_buy].userid.nunique()

# 方式2 点击-&gt;收藏-&gt;购买
pv_fav_df = pd.merge(left=pv_df,right=fav_df,how='inner',on=['userid','itemid','categoryid'],suffixes=('_pv','_fav'))
fav_buy_df = pd.merge(left=fav_df,right=buy_df,how='inner',on=['userid','itemid','categoryid'],suffixes=('_fav','_buy'))
count_user_pv_fav = pv_fav_df[pv_fav_df.time_pv &lt; pv_fav_df.time_fav].userid.nunique()
count_user_fav_buy = fav_buy_df[fav_buy_df.time_fav &lt; fav_buy_df.time_buy].userid.nunique()


# 方式3 点击-&gt;购买
pv_beh_buy_df = pd.merge(left=pv_df,right=buy_df,how='inner',on=['userid','itemid','categoryid'],suffixes=('_pv','_buy'))
count_user_pv_beh_buy = pv_beh_buy_df[pv_beh_buy_df.time_pv &lt; pv_beh_buy_df.time_buy].userid.nunique()
count_user_pv_buy = count_user_pv_beh_buy - count_users_cart_buy - count_user_fav_buy


print(count_users_cart_buy)
print(count_user_fav_buy)
print(count_user_pv_buy)
</code></pre>
<pre><code>2263
831
1573
</code></pre>
<pre><code class="language-python">fav_cart_ratio = (count_user_pv_fav+count_users_pv_cart)/total_unique_users
buy_beh_ratio=(count_user_fav_buy+count_users_cart_buy)/total_unique_users
buy_ratio = count_user_pv_buy /total_unique_users

print('收藏加购用户转化率为:%.2f%%'%(fav_cart_ratio*100))
print('收藏加购-&gt;购买用户转化率为:%.2f%%'%(buy_beh_ratio*100))
print('浏览直接购买用户转化率为:%.2f%%'%(buy_ratio*100))
</code></pre>
<pre><code>收藏加购用户转化率为:58.36%
收藏加购-&gt;购买用户转化率为:31.77%
浏览直接购买用户转化率为:16.15%
</code></pre>
<pre><code class="language-python">from pyecharts.charts import Funnel
# 漏斗图datapair
process_data_pair = [(&quot;点击量&quot;, total_unique_users), 
                     (&quot;收藏加购量&quot;, count_user_pv_fav+count_users_pv_cart),
                     (&quot;购买量&quot;, count_user_fav_buy+count_users_cart_buy)]
(
    Funnel(init_opts=opts.InitOpts(width='500px', height='400px'))
    .add(&quot;type&quot;, 
         data_pair=process_data_pair, 
         label_opts=opts.LabelOpts(position=&quot;top&quot;),
         gap=2,
         tooltip_opts=opts.TooltipOpts(is_show=True))
    .set_global_opts(title_opts=opts.TitleOpts(title=&quot;用户转化率&quot;, subtitle=&quot;process 浏览-&gt;收藏/加购-&gt;购买&quot;)) 
).render_notebook() 
</code></pre>
<figure data-type="image" tabindex="3"><img src="https://Angie-DA.github.io/post-images/1647759891955.png" alt="" loading="lazy"></figure>
<pre><code class="language-python">process_data_pair = [(&quot;点击量&quot;, total_unique_users), 
                     (&quot;购买量&quot;, count_user_pv_buy)]
(
    Funnel(init_opts=opts.InitOpts(width='500px', height='400px'))
    .add(&quot;type&quot;, 
         data_pair=process_data_pair, 
         label_opts=opts.LabelOpts(position=&quot;top&quot;),
         gap=2,
         tooltip_opts=opts.TooltipOpts(is_show=True))
    .set_global_opts(title_opts=opts.TitleOpts(title=&quot;用户转化率&quot;, subtitle=&quot;process 浏览-&gt;购买&quot;)) 
).render_notebook() 
</code></pre>
<figure data-type="image" tabindex="4"><img src="https://Angie-DA.github.io/post-images/1647759904810.png" alt="" loading="lazy"></figure>
<h5 id="柱状图-用户复购率">柱状图-用户复购率</h5>
<pre><code class="language-python">repurchase_users = user_type[user_type['buy']&gt;=2].shape[0]  # 购买记录超过1次的用户数
repurchase_rate = repurchase_users/user_bought_count
print(&quot;复购率:{:.2f}%&quot;.format(repurchase_rate*100))

# 进一步分析复购次数
sns.histplot(user_type[user_type['buy']&gt;=2]['buy']-1)
plt.show()
</code></pre>
<pre><code>复购率:66.21%
</code></pre>
<figure data-type="image" tabindex="5"><img src="https://Angie-DA.github.io/post-images/1647759921854.png" alt="" loading="lazy"></figure>
<p>结论：淘宝用户复购率能达到66.01%，但是进一步查看用户复购次数，发现绝大多数用户复购次数很少；</p>
<p>推测：淘宝的市场份额一直稳居前列，用户量足够庞大，足够的用户量复购一次也能提高复购率。</p>
<p>个人思考：在淘宝下沉扩展获取新用户的同时，促进老用户复购次数增加，进一步稳定提高复购率应是更重要的事情。购买一次可能是被吸睛的标题、精美的图片或是诱人的营销活动吸引，而复购就要求产品质量过关、服务到位，消费者对第一次的购物体验很满意才会进行第二次,所以淘宝可以重点在这些方面帮助商家。</p>
<h5 id="动态柱状-用户量变化趋势">动态柱状-用户量变化趋势</h5>
<p>1、每日的活跃用户量基本在71%左右，而成交客户基本维持在20%</p>
<p>2、2017/12/02和2017/12/03购买量和购买人数是上涨的，而活跃用户比例较前三天下降了一个百分点，且付费用户占比，ARPU、ARPPU均下降了一到两个百分点。</p>
<p>3、这9天内，用户活跃天数呈现正态分布，用户活跃天数主要集中在3-7天（用户当天操作记录达3条算作当天活跃）</p>
<p>当日UV、当日平均访问量，当日交易用户数、交易用户比例(当日交易用户数/当日UV)，当日ARPU(总交易量/当日UVor活跃用户数)、当日ARPPU(总交易量/当日交易用户数or活跃交易用户量)，当日活跃用户数(自定义“活跃”)；——用户量变化趋势图</p>
<pre><code class="language-python">behavior_types=list(dict(dataframe['type'].value_counts()).keys())
behavior_types
</code></pre>
<pre><code>['pv', 'cart', 'fav', 'buy']
</code></pre>
<pre><code class="language-python">groupby_date = dataframe.groupby(by=dataframe.date)                               # 根据日期分组
dates = sorted(list(dict(dataframe['date'].value_counts()).keys()))
dates_df = pd.DataFrame(data=None, index=dates, columns=behavior_types)           # 创建按日期分组的数据框

for d in dates:
    dates_df.loc[d] = groupby_date.get_group(d).type.value_counts()               # 按日期填充数据框

# 日期转换为星期，datetime.datetime.isoweekday（）返回的1-7代表周一--周日
dates_df['weekday'] = [datetime.datetime.isoweekday(datetime.date(x.year,x.month,x.day)) for x in dates_df.index]
dates_df
</code></pre>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>pv</th>
      <th>cart</th>
      <th>fav</th>
      <th>buy</th>
      <th>weekday</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2017-11-25</th>
      <td>93932</td>
      <td>5786</td>
      <td>2716</td>
      <td>1974</td>
      <td>6</td>
    </tr>
    <tr>
      <th>2017-11-26</th>
      <td>95657</td>
      <td>5784</td>
      <td>3113</td>
      <td>2022</td>
      <td>7</td>
    </tr>
    <tr>
      <th>2017-11-27</th>
      <td>87243</td>
      <td>5463</td>
      <td>2873</td>
      <td>2229</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2017-11-28</th>
      <td>88637</td>
      <td>5516</td>
      <td>2726</td>
      <td>2220</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2017-11-29</th>
      <td>91334</td>
      <td>5550</td>
      <td>3057</td>
      <td>2299</td>
      <td>3</td>
    </tr>
    <tr>
      <th>2017-11-30</th>
      <td>94735</td>
      <td>5638</td>
      <td>2891</td>
      <td>2323</td>
      <td>4</td>
    </tr>
    <tr>
      <th>2017-12-01</th>
      <td>98138</td>
      <td>6102</td>
      <td>2999</td>
      <td>2151</td>
      <td>5</td>
    </tr>
    <tr>
      <th>2017-12-02</th>
      <td>123514</td>
      <td>7829</td>
      <td>3895</td>
      <td>2536</td>
      <td>6</td>
    </tr>
    <tr>
      <th>2017-12-03</th>
      <td>122446</td>
      <td>7779</td>
      <td>3818</td>
      <td>2605</td>
      <td>7</td>
    </tr>
  </tbody>
</table>
<pre><code class="language-python">dates_df['uv'] = [groupby_date.get_group(d).userid.nunique() for d in dates]  # 每日独立访客量

# 自定义当天使用淘宝app进行5次操作（无论是查看详情页、收藏、加入购物车还是购买都算）的用户就是活跃用户
active_user_standard = 3                                                      # 自定义活跃用户操作次数基准
dates_df['dau'] = [(groupby_date.get_group(d).groupby(by='userid').size()&gt;active_user_standard).value_counts()[True] for d in dates]
dates_df['au_rate'] = dates_df['dau']/dates_df['uv']                          # 活跃用户比例
dates_df['buyer'] = dataframe[dataframe['type']=='buy'].groupby(by=['date','userid']).size().count(level=0)
dates_df['buyer_rate'] = dates_df['buyer']/dates_df['uv']                     # 付费用户比例
dates_df['ARPU'] = dates_df['buy']/dates_df['uv']                             # 人均购买量=总交易量/当日UV
dates_df['ARPPU'] = dates_df['buy']/dates_df['buyer']                         # 付费用户人均购买量
dates_df
</code></pre>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>pv</th>
      <th>cart</th>
      <th>fav</th>
      <th>buy</th>
      <th>weekday</th>
      <th>uv</th>
      <th>dau</th>
      <th>au_rate</th>
      <th>buyer</th>
      <th>buyer_rate</th>
      <th>ARPU</th>
      <th>ARPPU</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2017-11-25</th>
      <td>93932</td>
      <td>5786</td>
      <td>2716</td>
      <td>1974</td>
      <td>6</td>
      <td>6976</td>
      <td>5029</td>
      <td>0.720900</td>
      <td>1317</td>
      <td>0.188790</td>
      <td>0.28297</td>
      <td>1.498861</td>
    </tr>
    <tr>
      <th>2017-11-26</th>
      <td>95657</td>
      <td>5784</td>
      <td>3113</td>
      <td>2022</td>
      <td>7</td>
      <td>7128</td>
      <td>5143</td>
      <td>0.721521</td>
      <td>1324</td>
      <td>0.185746</td>
      <td>0.28367</td>
      <td>1.52719</td>
    </tr>
    <tr>
      <th>2017-11-27</th>
      <td>87243</td>
      <td>5463</td>
      <td>2873</td>
      <td>2229</td>
      <td>1</td>
      <td>7026</td>
      <td>5053</td>
      <td>0.719186</td>
      <td>1415</td>
      <td>0.201395</td>
      <td>0.31725</td>
      <td>1.575265</td>
    </tr>
    <tr>
      <th>2017-11-28</th>
      <td>88637</td>
      <td>5516</td>
      <td>2726</td>
      <td>2220</td>
      <td>2</td>
      <td>7032</td>
      <td>4965</td>
      <td>0.706058</td>
      <td>1410</td>
      <td>0.200512</td>
      <td>0.3157</td>
      <td>1.574468</td>
    </tr>
    <tr>
      <th>2017-11-29</th>
      <td>91334</td>
      <td>5550</td>
      <td>3057</td>
      <td>2299</td>
      <td>3</td>
      <td>7141</td>
      <td>5207</td>
      <td>0.729170</td>
      <td>1467</td>
      <td>0.205433</td>
      <td>0.321944</td>
      <td>1.567144</td>
    </tr>
    <tr>
      <th>2017-11-30</th>
      <td>94735</td>
      <td>5638</td>
      <td>2891</td>
      <td>2323</td>
      <td>4</td>
      <td>7243</td>
      <td>5226</td>
      <td>0.721524</td>
      <td>1476</td>
      <td>0.203783</td>
      <td>0.320723</td>
      <td>1.573848</td>
    </tr>
    <tr>
      <th>2017-12-01</th>
      <td>98138</td>
      <td>6102</td>
      <td>2999</td>
      <td>2151</td>
      <td>5</td>
      <td>7270</td>
      <td>5327</td>
      <td>0.732737</td>
      <td>1418</td>
      <td>0.195048</td>
      <td>0.295873</td>
      <td>1.516925</td>
    </tr>
    <tr>
      <th>2017-12-02</th>
      <td>123514</td>
      <td>7829</td>
      <td>3895</td>
      <td>2536</td>
      <td>6</td>
      <td>9567</td>
      <td>6811</td>
      <td>0.711926</td>
      <td>1726</td>
      <td>0.180412</td>
      <td>0.265078</td>
      <td>1.469293</td>
    </tr>
    <tr>
      <th>2017-12-03</th>
      <td>122446</td>
      <td>7779</td>
      <td>3818</td>
      <td>2605</td>
      <td>7</td>
      <td>9561</td>
      <td>6774</td>
      <td>0.708503</td>
      <td>1759</td>
      <td>0.183977</td>
      <td>0.272461</td>
      <td>1.480955</td>
    </tr>
  </tbody>
</table>
<pre><code class="language-python">(
    Line(init_opts=opts.InitOpts(width=&quot;800px&quot;, height=&quot;500px&quot;))
    .add_xaxis(xaxis_data=dates_df.index)
    .add_yaxis(&quot;uv&quot;, y_axis=dates_df['uv'],is_symbol_show=False)
    .add_yaxis(&quot;dau&quot;,y_axis=dates_df['dau'],is_symbol_show=False)
    .add_yaxis(&quot;buyer&quot;,y_axis=dates_df['buyer'],is_symbol_show=False)
    .set_global_opts(
        title_opts=opts.TitleOpts(title=&quot;用户量变化趋势&quot;, 
                                  subtitle=&quot;2017/11/25-2017/12/03期间用户量变化趋势&quot;),
        tooltip_opts=opts.TooltipOpts(trigger='axis'),
        toolbox_opts=opts.ToolboxOpts(is_show=True),
        xaxis_opts=opts.AxisOpts(type_='category', boundary_gap=False))
).render_notebook()
</code></pre>
<figure data-type="image" tabindex="6"><img src="https://Angie-DA.github.io/post-images/1647759938938.png" alt="" loading="lazy"></figure>
<h5 id="用户价值分析rfm分析recencyfrequencymonetary">用户价值分析——RFM分析（Recency，Frequency，Monetary）</h5>
<p>RFM模型通过一个客户的近期购买行为、购买的总体频率以及花了多少钱3项指标来描述该客户的价值状况。</p>
<p>R（Recency）：客户最近一次交易时间的间隔。R值越大，表示客户交易发生的日期越久，反之则表示客户交易发生的日期越近。<br>
F（Frequency）：客户在最近一段时间内交易的次数。F值越大，表示客户交易越频繁，反之则表示客户交易不够活跃。<br>
M（Monetary）：客户在最近一段时间内交易的金额。M值越大，表示客户价值越高，反之则表示客户价值越低。</p>
<p>本次分析数据集不含金额，因此仅从R、F两个维度进行分析</p>
<pre><code class="language-python"># R:Recency最近一次交易日期间隔；F:Frequency频率，交易次数
groupby_buy_userid = dataframe[dataframe['type']=='buy'].groupby(by='userid')
# 先创建一个空的DataFrame
RF = pd.DataFrame(index=groupby_buy_userid.groups.keys(), columns=['R', 'F'])

RF['F'] = groupby_buy_userid.type.count()
RF['last_buy_time'] = groupby_buy_userid.time.max()
# 假设获取数据集的第二天进行分析，所以选择2017/12/04为对照日期，保留天数
RF['R'] = (pd.to_datetime('2017-12-04')-RF['last_buy_time']).dt.days
</code></pre>
<pre><code class="language-python"># 最近的一次交易记录距离2017/12/04为0天
# 即12/03购买相差还不到一天，最远的为9天，平均为2.53天
# R划分4个区域 0-1,2-3,4-6,7-9,分别得分4，3，2，1

# 交易次数最少为1次最多为93次,平均3次
# 这里的3次分母是所有购买过商品的用户
# 而之前得出的人均购买次数2次分母是所有用户
# F划分4个区域 1,2,3,4+，分别得分1，2，3，4

RF[['R','F']].describe()
</code></pre>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>R</th>
      <th>F</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>6689.000000</td>
      <td>6689.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>2.524144</td>
      <td>3.043654</td>
    </tr>
    <tr>
      <th>std</th>
      <td>2.397553</td>
      <td>3.250811</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>0.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>2.000000</td>
      <td>2.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>4.000000</td>
      <td>4.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>8.000000</td>
      <td>72.000000</td>
    </tr>
  </tbody>
</table>
<pre><code class="language-python">def R_score(x):
    if 0 &lt;= x &lt;= 1:
        return 4
    elif 2 &lt;= x &lt;= 3:
        return 3
    elif 4 &lt;= x &lt;= 6:
        return 2
    elif 7 &lt;= x &lt;= 9:
        return 1
    else:
        return 0


def F_score(x):
    if x == 1:
        return 1
    elif x == 2:
        return 2
    elif x == 3:
        return 3
    elif x &gt;= 4:
        return 4
    else:
        return 0


# 根据R,F进行评分
RF['R_score'] = RF.R.map(R_score)
RF['F_score'] = RF.F.map(F_score)
</code></pre>
<pre><code class="language-python">RF['R&gt;mean?']=(RF['R_score']&gt;RF['R_score'].mean())*1
RF['F&gt;mean?']=(RF['F_score']&gt;RF['F_score'].mean())*1
</code></pre>
<pre><code class="language-python">def user_classfication(tup):
    R_score, F_score = tup
    if R_score == 0 and F_score == 1:
        return &quot;重要保持客户&quot;
    elif R_score == 1 and F_score == 0:
        return &quot;重要发展客户&quot;
    elif R_score == 1 and F_score == 1:
        return &quot;重要价值客户&quot;
    elif R_score == 0 and F_score == 0:
        return &quot;重要挽留客户&quot;
    else:
        return None
    
RF['user_classification'] = RF[['R&gt;mean?','F&gt;mean?']].apply(user_classfication, axis=1)
RF.head()
</code></pre>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>R</th>
      <th>F</th>
      <th>last_buy_time</th>
      <th>R_score</th>
      <th>F_score</th>
      <th>R&gt;mean?</th>
      <th>F&gt;mean?</th>
      <th>user_classification</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>100</th>
      <td>5</td>
      <td>8</td>
      <td>2017-11-28 09:51:17</td>
      <td>2</td>
      <td>4</td>
      <td>0</td>
      <td>1</td>
      <td>重要保持客户</td>
    </tr>
    <tr>
      <th>117</th>
      <td>5</td>
      <td>10</td>
      <td>2017-11-28 16:09:39</td>
      <td>2</td>
      <td>4</td>
      <td>0</td>
      <td>1</td>
      <td>重要保持客户</td>
    </tr>
    <tr>
      <th>119</th>
      <td>4</td>
      <td>3</td>
      <td>2017-11-29 20:43:31</td>
      <td>2</td>
      <td>3</td>
      <td>0</td>
      <td>1</td>
      <td>重要保持客户</td>
    </tr>
    <tr>
      <th>121</th>
      <td>8</td>
      <td>1</td>
      <td>2017-11-25 22:17:35</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>重要挽留客户</td>
    </tr>
    <tr>
      <th>122</th>
      <td>1</td>
      <td>3</td>
      <td>2017-12-02 13:59:07</td>
      <td>4</td>
      <td>3</td>
      <td>1</td>
      <td>1</td>
      <td>重要价值客户</td>
    </tr>
  </tbody>
</table>
<pre><code class="language-python"># 统计用户分类情况
RF.user_classification.value_counts()
</code></pre>
<pre><code>重要挽留客户    2465
重要价值客户    1667
重要发展客户    1369
重要保持客户    1188
Name: user_classification, dtype: int64
</code></pre>
<pre><code class="language-python"># 用户分类占比
RF.user_classification.value_counts(1)
</code></pre>
<pre><code>重要挽留客户    0.368515
重要价值客户    0.249215
重要发展客户    0.204664
重要保持客户    0.177605
Name: user_classification, dtype: float64
</code></pre>
<p>根据RFM模型对用户分类后发现重要挽留客户比例最高，其次是重要价值用户，淘宝作为成熟的电子商务平台，重要价值客户达到了一定的比例，在其他电商平台相继发展的大环境下，淘宝应该注重重要挽留客户，但是淘宝目前是中国最受欢迎的电商平台，目前只要保证口碑，适当营销并推出一系列的活动就能稳固部分重要挽留客户，同时，需要提高社群管理的效率，将重要保持客户和重要发展客户转变为重要价值客户，可采取定期发送文案、赠送优惠券等方式。要抓住用户渴望被认同、提升优越感、爱占便宜等心理进行考虑。</p>
<h5 id="箱型图-用户消费习惯分析">箱型图-用户消费习惯分析</h5>
<pre><code class="language-python"># 用户习惯消费时间点分析
data_user_buy=dataframe[dataframe.type=='buy']

from pyecharts import options as opts
from pyecharts.charts import Boxplot
df = pd.DataFrame(data_user_buy['hour'])
df.plot.box(title=&quot;用户下单时间&quot;)
plt.grid(linestyle=&quot;--&quot;)
plt.show()
</code></pre>
<figure data-type="image" tabindex="7"><img src="https://Angie-DA.github.io/post-images/1647759950839.png" alt="" loading="lazy"></figure>
<p>个人思考：对产生过购买行为的用户分析消费时间可知，下单次数最多最密集的时间点分布在11-19点之间，中午和下午用户最习惯产生消费。为了促进消费量，商家可以在此时间点开始促销活动。</p>
<h3 id="商品数据分析">商品数据分析</h3>
<h4 id="条形图-热门商品分析">条形图-热门商品分析</h4>
<p>分别对点击量、收藏量、加购量和购买量前十的商品大类进行分析。</p>
<pre><code class="language-python">matplotlib.use('Qt5Agg')
import matplotlib.pyplot as plt

groupby_itemid = dataframe.groupby(by='itemid')                               # 按商品分组
item_type_df = groupby_itemid.type.value_counts().unstack()                   # 展开为一个dataframe
item_type_df.replace(to_replace=np.nan, value=0, inplace=True)                # 缺失值补0

item_pv_df = item_type_df.sort_values(by='pv', ascending=False)              # 按浏览量降序排列
item_cart_df = item_type_df.sort_values(by='cart', ascending=False)          # 按加购量降序排列
item_fav_df = item_type_df.sort_values(by='fav', ascending=False)            # 按收藏量降序排列
item_buy_df = item_type_df.sort_values(by='buy', ascending=False)            # 按购买量降序排列


</code></pre>
<pre><code class="language-python">item_pv_df = item_pv_df.head(10)

plt.barh(range(10),item_pv_df['pv'], tick_label=item_pv_df.index)
plt.ylabel('itemid')
plt.xlabel('pv')
plt.title('点击量前十的商品')
plt.show()
</code></pre>
<figure data-type="image" tabindex="8"><img src="https://Angie-DA.github.io/post-images/1647759969231.png" alt="" loading="lazy"></figure>
<pre><code class="language-python">item_cart_df = item_cart_df.head(10)

plt.barh(range(10),item_cart_df['cart'], tick_label=item_cart_df.index)
plt.ylabel('itemid')
plt.xlabel('cart')
plt.title('加购量前十的商品')
plt.show()
</code></pre>
<figure data-type="image" tabindex="9"><img src="https://Angie-DA.github.io/post-images/1647759992631.png" alt="" loading="lazy"></figure>
<pre><code class="language-python">item_fav_df = item_fav_df.head(10)

plt.barh(range(10),item_fav_df['fav'], tick_label=item_fav_df.index)
plt.ylabel('itemid')
plt.xlabel('fav')
plt.title('收藏量前十的商品')
plt.show()
</code></pre>
<figure data-type="image" tabindex="10"><img src="https://Angie-DA.github.io/post-images/1647760014292.png" alt="" loading="lazy"></figure>
<pre><code class="language-python">item_buy_df = item_buy_df.head(10)

plt.barh(range(10),item_buy_df['buy'], tick_label=item_buy_df.index)
plt.ylabel('itemid')
plt.xlabel('buy')
plt.title('购买量前十的商品')
plt.show()
</code></pre>
<figure data-type="image" tabindex="11"><img src="https://Angie-DA.github.io/post-images/1647760030039.png" alt="" loading="lazy"></figure>
<h4 id="韦恩图-热门商品分析">韦恩图-热门商品分析</h4>
<pre><code class="language-python">#添加pyvenn路径
import sys
sys.path.append(r'path\pyvenn-master')
import venn
labels = venn.get_labels([set(item_pv_df.index), 
                          set(item_cart_df.index), 
                          set(item_fav_df.index), 
                          set(item_buy_df.index)], 
                         fill=['number', 'percent']
                         )

fig, ax = venn.venn4(labels, names=['pv','cart','fav','buy'])
plt.title('韦恩图')
fig.show()
</code></pre>
<figure data-type="image" tabindex="12"><img src="https://Angie-DA.github.io/post-images/1647760042704.png" alt="" loading="lazy"></figure>
<p>个人思考：根据条形图可以看出点击量、收藏量、加购量和购买量前几名较后几名差距不大，说明没有爆款的出现。</p>
<p>根据四者韦恩图可以看出，购买量前十品类与其他三者的重合度却没有那么高，说明对于部分品类商品而言，虽然能吸引许多用户，但是购买转化率却相对较低，这部分产品的转化率有提升空间。</p>

              </div>
              <div class="toc-container">
                <ul class="markdownIt-TOC">
<li>
<ul>
<li>
<ul>
<li><a href="#%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%8F%96">数据读取</a>
<ul>
<li><a href="#%E6%9F%A5%E7%9C%8B%E6%95%B0%E6%8D%AE%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BF%A1%E6%81%AF">查看数据的基本信息</a></li>
</ul>
</li>
<li><a href="#%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97">数据清洗</a>
<ul>
<li><a href="#%E6%9F%A5%E7%9C%8B%E6%95%B0%E6%8D%AE%E6%B2%A1%E6%9C%89%E7%A9%BA%E5%80%BC%E7%9A%84%E6%95%B0%E6%8D%AE%E7%9A%84%E4%B8%AA%E6%95%B0">查看数据没有空值的数据的个数</a></li>
<li><a href="#%E6%9F%A5%E7%9C%8B%E6%95%B0%E6%8D%AE%E7%9A%84%E5%89%8Dn%E6%9D%A1">查看数据的前n条</a></li>
<li><a href="#%E8%BD%AC%E6%8D%A2%E7%B1%BB%E5%9E%8B-%E6%88%AA%E5%8F%96%E6%95%B0%E6%8D%AE-%E9%87%8D%E6%96%B0%E6%8E%92%E5%88%97">转换类型、截取数据、重新排列</a></li>
<li><a href="#%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97%E7%BB%93%E6%9E%9C">数据清洗结果</a></li>
</ul>
</li>
<li><a href="#%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90">用户数据分析</a>
<ul>
<li><a href="#%E8%BE%93%E5%87%BA%E5%BD%93%E5%89%8D%E6%95%B0%E6%8D%AE%E5%90%84%E6%A0%8F%E7%9B%AE%E8%AE%A1%E6%95%B0">输出当前数据各栏目计数</a></li>
<li><a href="#%E7%94%A8%E6%88%B7%E5%A4%8D%E8%B4%AD%E7%8E%87">用户复购率</a></li>
<li><a href="#%E5%8F%AF%E8%A7%86%E5%8C%96%E5%9B%BE%E8%A1%A8">可视化图表</a>
<ul>
<li><a href="#%E9%A5%BC%E5%9B%BE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA%E5%8D%A0%E6%AF%94">饼图-用户行为占比</a></li>
<li><a href="#%E5%8A%A8%E6%80%81%E6%9B%B2%E7%BA%BF-%E6%AF%8F%E6%97%A5pv-uv">动态曲线-每日pv、uv</a></li>
<li><a href="#%E6%BC%8F%E6%96%97%E5%9B%BE-%E7%94%A8%E6%88%B7%E8%A1%8C%E4%B8%BA">漏斗图-用户行为</a></li>
<li><a href="#%E6%9F%B1%E7%8A%B6%E5%9B%BE-%E7%94%A8%E6%88%B7%E5%A4%8D%E8%B4%AD%E7%8E%87">柱状图-用户复购率</a></li>
<li><a href="#%E5%8A%A8%E6%80%81%E6%9F%B1%E7%8A%B6-%E7%94%A8%E6%88%B7%E9%87%8F%E5%8F%98%E5%8C%96%E8%B6%8B%E5%8A%BF">动态柱状-用户量变化趋势</a></li>
<li><a href="#%E7%94%A8%E6%88%B7%E4%BB%B7%E5%80%BC%E5%88%86%E6%9E%90rfm%E5%88%86%E6%9E%90recencyfrequencymonetary">用户价值分析——RFM分析（Recency，Frequency，Monetary）</a></li>
<li><a href="#%E7%AE%B1%E5%9E%8B%E5%9B%BE-%E7%94%A8%E6%88%B7%E6%B6%88%E8%B4%B9%E4%B9%A0%E6%83%AF%E5%88%86%E6%9E%90">箱型图-用户消费习惯分析</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#%E5%95%86%E5%93%81%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90">商品数据分析</a>
<ul>
<li><a href="#%E6%9D%A1%E5%BD%A2%E5%9B%BE-%E7%83%AD%E9%97%A8%E5%95%86%E5%93%81%E5%88%86%E6%9E%90">条形图-热门商品分析</a></li>
<li><a href="#%E9%9F%A6%E6%81%A9%E5%9B%BE-%E7%83%AD%E9%97%A8%E5%95%86%E5%93%81%E5%88%86%E6%9E%90">韦恩图-热门商品分析</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

              </div>
            </div>
          </article>
        </div>

        
          <div class="next-post">
            <div class="next">下一篇</div>
            <a href="https://Angie-DA.github.io/9Dtl7YqLP/">
              <h3 class="post-title">
                Tableau实现连锁门店日营业情况数据监控
              </h3>
            </a>
          </div>
        

        

        <div class="site-footer">
  
  <a class="rss" href="https://Angie-DA.github.io/atom.xml" target="_blank">
    <i class="ri-rss-line"></i> RSS
  </a>
</div>

      </div>
    </div>

    <script>
      hljs.initHighlightingOnLoad()

      let mainNavLinks = document.querySelectorAll(".markdownIt-TOC a");

      // This should probably be throttled.
      // Especially because it triggers during smooth scrolling.
      // https://lodash.com/docs/4.17.10#throttle
      // You could do like...
      // window.addEventListener("scroll", () => {
      //    _.throttle(doThatStuff, 100);
      // });
      // Only not doing it here to keep this Pen dependency-free.

      window.addEventListener("scroll", event => {
        let fromTop = window.scrollY;

        mainNavLinks.forEach((link, index) => {
          let section = document.getElementById(decodeURI(link.hash).substring(1));
          let nextSection = null
          if (mainNavLinks[index + 1]) {
            nextSection = document.getElementById(decodeURI(mainNavLinks[index + 1].hash).substring(1));
          }
          if (section.offsetTop <= fromTop) {
            if (nextSection) {
              if (nextSection.offsetTop > fromTop) {
                link.classList.add("current");
              } else {
                link.classList.remove("current");    
              }
            } else {
              link.classList.add("current");
            }
          } else {
            link.classList.remove("current");
          }
        });
      });

    </script>
  </body>
</html>
